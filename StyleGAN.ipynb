{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZDlo+l75muwaA5jjPlYXI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dude123studios/AdvancedGenerativeLearning/blob/main/StyleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNtoNjwd-Mmx",
        "outputId": "39c08797-136a-4965-93cc-0e6a337a85f7"
      },
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 679 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lEgv4zKnH9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09cfe9d-c78d-4030-8464-c85f5009051b"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "import gdown\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from enum import Enum\n",
        "from glob import glob\n",
        "from functools import partial\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer,Input, LeakyReLU, Reshape\n",
        "from tensorflow.keras.layers import UpSampling2D, AveragePooling2D, Flatten\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "\n",
        "\n",
        "CKPT_PATH = './ckpt'\n",
        "RESULT_PATH = './results'\n",
        "os.makedirs(CKPT_PATH, exist_ok=True)\n",
        "os.makedirs(RESULT_PATH, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_sJh8VYnjVD"
      },
      "source": [
        "url = \"https://drive.google.com/uc?id=17w_hePC1xO2eX83gAAF8ptKC59mTPQiL\" \n",
        "gdown.download(url, 'celeba_hq.zip', quiet=False)\n",
        "!unzip celeba_hq.zip -d ./celeba_hq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf1HEcCBnpST"
      },
      "source": [
        "def load(res, image_file):\n",
        "    image = tf.io.read_file(image_file)\n",
        "    image = tf.image.decode_jpeg(image)\n",
        "    image = tf.image.resize(image, [res, res],\n",
        "                            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image /127.5) - 1\n",
        "    return image\n",
        "\n",
        "BATCH_SIZE = {2: 16, 3: 16, 4: 16, 5: 16, 6: 16, 7: 8, 8: 4, 9: 2, 10:1}\n",
        "TRAIN_STEP_RATIO = {k: BATCH_SIZE[2]/v for k, v in BATCH_SIZE.items()}\n",
        "\n",
        "def create_dataset_(data_path, res):\n",
        "    res_log2 = int(np.log2(res))\n",
        "    BUFFER_SIZE = 200\n",
        "    images = glob(data_path)\n",
        "    random.shuffle(images)\n",
        "    batch_size = BATCH_SIZE[res_log2]\n",
        "    tf_list = tf.data.Dataset.from_tensor_slices(images)\n",
        "    dataset = tf_list.map(partial(load, res),  num_parallel_calls= tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE).batch(batch_size, drop_remainder=True).repeat()\n",
        "    return dataset\n",
        "\n",
        "DATA_PATH = \"celeba_hq/train/**/*.jpg\"\n",
        "create_dataset = partial(create_dataset_, DATA_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBfwrSinri7"
      },
      "source": [
        "def plot_images(images, log2_res, fname=''):    \n",
        "    scales = {2:0.5,\n",
        "             3:1,\n",
        "             4:2,\n",
        "             5:3,\n",
        "             6:4,\n",
        "             7:5,\n",
        "             8:6,\n",
        "             9:7,\n",
        "             10:8}\n",
        "    scale = scales[log2_res]\n",
        "    \n",
        "    grid_col = min(images.shape[0], int(32//scale))\n",
        "    grid_row = 1\n",
        "\n",
        "    f, axarr = plt.subplots(grid_row, grid_col, figsize=(grid_col*scale, grid_row*scale))\n",
        "\n",
        "    for row in range(grid_row):\n",
        "        ax = axarr if grid_row==1 else axarr[row]\n",
        "        for col in range(grid_col):\n",
        "            ax[col].imshow((images[row*grid_col + col] + 1.)/2.)\n",
        "            ax[col].axis('off')\n",
        "    plt.show()\n",
        "    if fname:\n",
        "        print(\"image name\", fname)\n",
        "        f.savefig(fname)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EH8FkwinyCz"
      },
      "source": [
        "def fade_in(alpha, a, b):\n",
        "    \n",
        "    return alpha * a + (1. - alpha) * b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUKgm8vLn0HC"
      },
      "source": [
        "def wasserstein_loss(y_true, y_pred):\n",
        "    \n",
        "    return -tf.reduce_mean(y_true * y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOPhfmqvn1Eq"
      },
      "source": [
        "class PixelNorm(Layer):\n",
        "    def __init__(self, epsilon=1e-8):\n",
        "        super(PixelNorm, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "        \n",
        "    def call(self, input_tensor):\n",
        "        return input_tensor / tf.math.sqrt(tf.reduce_mean(input_tensor**2, axis=-1, keepdims=True) + self.epsilon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_dQqxTGn61a"
      },
      "source": [
        "def minibatch_std(input_tensor, epsilon=1e-8):\n",
        "    n, h, w, c = tf.shape(input_tensor)\n",
        "    group_size = tf.minimum(4, n)\n",
        "    x = tf.reshape(input_tensor, [group_size, -1, h, w, c]) \n",
        "    group_mean, group_var = tf.nn.moments(x, axes=(0), keepdims=False) \n",
        "    group_std = tf.sqrt(group_var + epsilon) \n",
        "    avg_std = tf.reduce_mean(group_std, axis=[1,2,3], keepdims=True) \n",
        "    x = tf.tile(avg_std, [group_size, h, w, 1]) \n",
        "\n",
        "    return tf.concat([input_tensor, x], axis=-1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmseXay4n9mb"
      },
      "source": [
        "class ConvBlock(Layer):\n",
        "    def __init__(self, out_channels, kernel=3, gain=2, **kwargs):\n",
        "        super(ConvBlock, self).__init__(kwargs)\n",
        "        self.kernel = kernel\n",
        "        self.out_channels = out_channels\n",
        "        self.gain = gain\n",
        "        self.pad = kernel!=1\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.in_channels = input_shape[-1]\n",
        "\n",
        "        initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)        \n",
        "        self.w = self.add_weight(shape=[self.kernel,\n",
        "                                        self.kernel,\n",
        "                                        self.in_channels,\n",
        "                                        self.out_channels],\n",
        "                                initializer=initializer,\n",
        "                                trainable=True, name='kernel')\n",
        "        \n",
        "        self.b = self.add_weight(shape=(self.out_channels,),\n",
        "                                initializer='zeros',\n",
        "                                trainable=True, name='bias')\n",
        "        \n",
        "        fan_in = self.kernel*self.kernel*self.in_channels\n",
        "        self.scale = tf.sqrt(self.gain/fan_in)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        if self.pad:\n",
        "            x = tf.pad(inputs, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n",
        "        else:\n",
        "            x = inputs\n",
        "        output = tf.nn.conv2d(x, self.scale*self.w, strides=1, padding=\"VALID\") + self.b\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37Nr1Cujn_R0"
      },
      "source": [
        "class DenseBlock(Layer):\n",
        "    def __init__(self, units, gain=2, lrmul=1, **kwargs):\n",
        "        super(DenseBlock, self).__init__(kwargs)\n",
        "        self.units = units\n",
        "        self.gain = gain\n",
        "        self.lrmul = lrmul\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.in_channels = input_shape[-1]\n",
        "        initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1./self.lrmul)        \n",
        "        self.w = self.add_weight(shape=[self.in_channels,\n",
        "                                        self.units],\n",
        "                                initializer=initializer,\n",
        "                                trainable=True, name='kernel')\n",
        "        \n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                                initializer='zeros',\n",
        "                                trainable=True, name='bias')\n",
        "        \n",
        "        fan_in = self.in_channels\n",
        "        self.scale = tf.sqrt(self.gain/fan_in)\n",
        "        \n",
        "    @tf.function(experimental_relax_shapes=True)\n",
        "    def call(self, inputs):\n",
        "        output = tf.add(tf.matmul(inputs, self.scale*self.w), self.b)\n",
        "        return output*self.lrmul"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbk4E-a9oB2a"
      },
      "source": [
        "class AddNoise(Layer):\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        n, h, w, c = input_shape[0]\n",
        "\n",
        "        initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
        "        self.B = self.add_weight(shape=[1, 1, 1, c],\n",
        "                                initializer=initializer,\n",
        "                                trainable=True, name='kernel')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        x, noise = inputs\n",
        "        output = x * self.B + noise\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHQvFo1GokLy"
      },
      "source": [
        "class AdaIN(Layer):\n",
        "    def __init__(self, gain=1, **kwargs):\n",
        "        super(AdaIN, self).__init__(kwargs)\n",
        "        self.gain = gain\n",
        "        \n",
        "    def build(self, input_shapes):\n",
        "        x_shape = input_shapes[0]\n",
        "        w_shape = input_shapes[1]\n",
        "\n",
        "        self.w_channels = w_shape[-1]\n",
        "        self.x_channels = x_shape[-1]\n",
        "        \n",
        "        self.dense_1 = DenseBlock(self.x_channels, gain=1)\n",
        "        self.dense_2 = DenseBlock(self.x_channels, gain=1)\n",
        "        \n",
        "    @tf.function(experimental_relax_shapes=True)        \n",
        "    def call(self, inputs):\n",
        "        x, w = inputs\n",
        "        ys = tf.reshape(self.dense_1(w), (-1, 1, 1, self.x_channels))\n",
        "        yb = tf.reshape(self.dense_2(w), (-1, 1, 1, self.x_channels))\n",
        "        \n",
        "        output = ys*x + yb\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0t9XYZtpGYM"
      },
      "source": [
        "def Mapping(num_stages, input_shape=512):\n",
        "    z = Input(input_shape)\n",
        "    w = PixelNorm()(z)\n",
        "\n",
        "    for _ in range(num_stages):\n",
        "        w = DenseBlock(input_shape, lrml=1e-2)(w)\n",
        "        w = LeakyReLU(0.2)(w)\n",
        "    \n",
        "    w = tf.tile(tf.expand_dims(w, 1), (1, num_stages, 1))\n",
        "    \n",
        "    return Model(z, w, name='mapping')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb5OWhfTxYs0"
      },
      "source": [
        "def GenBlock(filter_num, res, input_shape, is_base):\n",
        "\n",
        "    input_tensor = Input(shape=input_shape, name=f'g_{res}')\n",
        "    noise = Input(shape=(res, res, 1), name=f'noise_{res}')\n",
        "    w = Input(shape=512)\n",
        "    \n",
        "    x = input_tensor        \n",
        "\n",
        "    if not is_base:\n",
        "        x = UpSampling2D((2,2))(x)\n",
        "        x = ConvBlock(filter_num, 3)(x)\n",
        "\n",
        "    x = AddNoise()([x, noise])\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = InstanceNormalization()(x)\n",
        "    x = AdaIN()([x, w])\n",
        "\n",
        "    # ADD NOISE\n",
        "    x = ConvBlock(filter_num, 3)(x)\n",
        "    x = AddNoise()([x, noise])\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = InstanceNormalization()(x)      \n",
        "    x = AdaIN()([x, w])\n",
        "\n",
        "    return Model([input_tensor, w, noise], x, \n",
        "                 name=f'genblock_{res}x{res}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV8OhO6OyNkD"
      },
      "source": [
        "def DiscBase(filter_num, res):\n",
        "\n",
        "    input_tensor = Input(shape=(res, res, filter_num), name=f'd_{res}')\n",
        "    x = minibatch_std(input_tensor)\n",
        "    x = ConvBlock(filter_num, 3)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = DenseBlock(filter_num)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = DenseBlock(1)(x)\n",
        "\n",
        "    return Model(input_tensor, x, name=f'd_base')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbW7orNpBUui"
      },
      "source": [
        "def DiscBlock(filter_num_1, filter_num_2, res):\n",
        "    return Sequential([Input(shape=(res, res, filter_num_1), name=f'd_{res}'),\n",
        "                       ConvBlock(filter_num_1, 3),\n",
        "                       LeakyReLU(0.2),\n",
        "                       ConvBlock(filter_num_2, 3),\n",
        "                       LeakyReLU(0.2),\n",
        "                       AveragePooling2D((2,2))\n",
        "                      ], name=f'd_{res}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNpek6KaD8V8"
      },
      "source": [
        "class Phase(Enum):\n",
        "    TRANSITION = 1\n",
        "    STABLE = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpyZEmJVEB68"
      },
      "source": [
        "class StyleGAN(Model):\n",
        "\n",
        "    @staticmethod\n",
        "    def log2(res):\n",
        "        return int(np.log2(res))\n",
        "    \n",
        "    def __init__(self, z_dim=512, target_res=256, start_res=4):\n",
        "        super(StyleGAN, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.target_res_log2 = self.log2(target_res)\n",
        "        self.start_res_log2 = self.log2(start_res)\n",
        "\n",
        "        self.current_res_log2 = self.target_res_log2\n",
        "\n",
        "        self.num_stages = self.current_res_log2 - self.start_res_log2 + 1\n",
        "\n",
        "        self.filter_nums = {\n",
        "            0: 512,\n",
        "            1: 512,\n",
        "            2: 512, # 4x4\n",
        "            3: 512, # 8x8\n",
        "            4: 512, # 16x16\n",
        "            5: 512, # 32x32\n",
        "            6: 256, # 64x64\n",
        "            7: 128, # 128x128\n",
        "            8: 64,  # 256x256\n",
        "            9: 32,  # 512x512\n",
        "            10: 16 # 1024x1024 \n",
        "        }\n",
        "\n",
        "        self.g_input_shape = (start_res, start_res, self.filter_nums[self.start_res_log2])\n",
        "        self.g_input = Input(self.g_input_shape)\n",
        "        self.mapping = Mapping(num_stages=self.num_stages)\n",
        "        self.build_generators()\n",
        "        self.build_discriminators()\n",
        "        \n",
        "        self.phase = Phase.STABLE\n",
        "        self.alpha = tf.Variable(1., dtype=tf.float32, trainable=False, name='alpha')\n",
        "        self.train_step_counter = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
        "\n",
        "        self.loss_weights = {'gradient_penalty': 10, 'drift': 0.001}\n",
        "    \n",
        "    def build_generators(self):\n",
        "\n",
        "        self.to_rgb = []\n",
        "        self.g_blocks = []\n",
        "        self.noise_inputs = []\n",
        "\n",
        "        for i in range(self.start_res_log2, self.target_res_log2 + 1):\n",
        "            filter_num = self.filter_nums[i]\n",
        "            res = 2**i\n",
        "            self.noise_inputs.append(Input(shape=(res, res, 1), name=f'noise_{res}_x_{res}'))\n",
        "            to_rgb = Sequential([Input(shape=(res, res, filter_num)), ConvBlock(3, 1, gain=1, activation=None)], name=f'to_rgb_{res}_x_{res}')\n",
        "            self.to_rgb.append(to_rgb)\n",
        "            is_base = i == self.start_res_log2\n",
        "            if is_base:\n",
        "                input_shape = (res, res, self.filter_nums[i-1])\n",
        "            else:\n",
        "                input_shape = (2**(i-1), 2**(i-1), self.filter_nums[i-1])\n",
        "            self.g_blocks.append(GenBlock(filter_num, res, input_shape, is_base))\n",
        "\n",
        "    def build_discriminators(self):\n",
        "        self.from_rgb = []\n",
        "        self.d_blocks = []\n",
        "        \n",
        "        for res_log2 in range(self.start_res_log2, self.target_res_log2 + 1):\n",
        "            res = 2**res_log2\n",
        "            filter_num = self.filter_nums[res_log2]\n",
        "            from_rgb = Sequential([Input(shape=(res, res, 3), name=f'from_rgb_input_{res}'), \n",
        "                                    ConvBlock(filter_num, 1),\n",
        "                                    LeakyReLU(0.2)], name=f'from_rgb_{res}')\n",
        "            \n",
        "            self.from_rgb.append(from_rgb)\n",
        "            \n",
        "            \n",
        "            input_shape = (res, res, filter_num)\n",
        "            if len(self.d_blocks) == 0:                \n",
        "                d_block = DiscBase(filter_num, res)\n",
        "            else:\n",
        "                d_block = DiscBlock(filter_num, self.filter_nums[res_log2-1], res)\n",
        "                \n",
        "            self.d_blocks.append(d_block)\n",
        "    \n",
        "    def grow_g(self, res):\n",
        "        \n",
        "        num_stages = self.log2(res) - self.start_res_log2 + 1\n",
        "        w = Input(shape=(self.num_stages, 512), name='w')\n",
        "        \n",
        "        x = self.g_blocks[0]([self.g_input, w[:,0], \n",
        "                             self.noise_inputs[0]])\n",
        "\n",
        "        if num_stages == 1:            \n",
        "            rgb  = self.to_rgb[0](x)            \n",
        "        else:            \n",
        "            for i in range(1, num_stages-1):\n",
        "            \n",
        "                x = self.g_blocks[i]([x, w[:,i], \n",
        "                                     self.noise_inputs[i]])\n",
        "            \n",
        "            old_rgb = self.to_rgb[num_stages-2](x)\n",
        "            old_rgb = UpSampling2D((2,2))(old_rgb)\n",
        "\n",
        "            i = num_stages - 1\n",
        "            x = self.g_blocks[i]([x, w[:,i], \n",
        "                                 self.noise_inputs[i]])\n",
        "\n",
        "            new_rgb = self.to_rgb[i](x)\n",
        "\n",
        "            rgb = fade_in(self.alpha, new_rgb, old_rgb)\n",
        "        \n",
        "        self.generator = Model([self.g_input, w, self.noise_inputs], \n",
        "                                rgb, \n",
        "                        name=f'generator_{res}_x_{res}')  \n",
        "        \n",
        "    \n",
        "    def grow_d(self, res):\n",
        "\n",
        "        idx = self.log2(res) - self.start_res_log2\n",
        "\n",
        "        input_image = Input(shape=(res, res, 3), name='input_image')\n",
        "\n",
        "        x = self.from_rgb[idx](input_image)\n",
        "        x = self.d_blocks[idx](x)\n",
        "\n",
        "        if idx > 0:\n",
        "            idx -= 1\n",
        "            downsized_image = AveragePooling2D((2, 2))(input_image)\n",
        "            y = self.from_rgb[idx](downsized_image)\n",
        "\n",
        "            x = fade_in(self.alpha, x, y)\n",
        "\n",
        "            for i in range(idx, -1, -1):\n",
        "                x = self.d_blocks[i](x)\n",
        "            \n",
        "        \n",
        "        self.discriminator = Model(input_image, x, name=f'discriminator_{res}_x_{res}')\n",
        "    \n",
        "\n",
        "    def grow_model(self, res):\n",
        "        tf.keras.backend.clear_session()\n",
        "        res_log2 = self.log2(res)\n",
        "        self.current_res_log2 = res_log2\n",
        "        \n",
        "        self.grow_g(res)\n",
        "        self.grow_d(res)\n",
        "    \n",
        "\n",
        "    def compile(self, steps_per_epoch, phase, res, d_optimizer, g_optimizer, \n",
        "                *args, **kwargs):\n",
        "        \n",
        "        self.loss_weights = kwargs.pop('loss_weights', self.loss_weights)\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        if res != 2**self.current_res_log2:\n",
        "            self.grow_model(res)\n",
        "            self.g_optimizer = g_optimizer\n",
        "            self.d_optimizer = d_optimizer\n",
        "        \n",
        "        self.train_step_counter.assign(0)\n",
        "        self.phase = phase\n",
        "        super(StyleGAN, self).compile(*args, **kwargs)\n",
        "    \n",
        "    def generate_noise(self, batch_size):\n",
        "        noise = [tf.random.normal((batch_size, 2**res, 2**res)) \n",
        "            for res in range(self.start_res_log2, self.target_res_log2 + 1)]\n",
        "        \n",
        "        return noise\n",
        "    \n",
        "    def gradient_loss(self, grad):\n",
        "        #Normalize\n",
        "        loss = tf.square(grad)\n",
        "        loss = tf.reduce_sum(loss, axis=np.arange(1, len(tf.shape(loss))))\n",
        "        loss = tf.sqrt(loss)\n",
        "\n",
        "        #Compute distance from 1\n",
        "        loss = tf.reduce_mean(tf.square(loss - 1))\n",
        "\n",
        "        return loss\n",
        "    \n",
        "    def train_step(self, inputs):\n",
        "\n",
        "        self.train_step_counter.assign_add(1)\n",
        "\n",
        "        if self.phase == Phase.TRANSITION:\n",
        "            self.alpha.assign_add(tf.cast(self.train_step_counter/self.steps_per_epoch, tf.float32))\n",
        "        elif self.phase == Phase.STABLE:\n",
        "            self.alpha.assign(1.)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        \n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        real_labels = tf.ones(batch_size)\n",
        "        fake_labels = tf.zeros(batch_size)\n",
        "\n",
        "        z = tf.random.normal((batch_size, self.z_dim))\n",
        "        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n",
        "        noise = self.generator_noise(self, batch_size)\n",
        "\n",
        "        with tf.GradientTape() as g_tape:\n",
        "            w = self.mapping(z)\n",
        "            fake_images = self.generator([const_input, w, noise])\n",
        "            fake_preds = self.discriminator(fake_images)\n",
        "            g_loss = wasserstien_loss(real_labels, fake_preds)\n",
        "        \n",
        "        vars = self.mapping.variables + self.generator.variables\n",
        "        gradients = tape.gradient(g_loss, vars)\n",
        "        self.g_optimizer.apply_gradients(zip(gradients, vars))\n",
        "\n",
        "        with tf.GradientTape() as d_tape,\\\n",
        "            tf.GradientTape() as gradient_tape:\n",
        "\n",
        "            pred_fake = self.discriminator(fake_images)\n",
        "            pred_real - self.discriminator(inputs)\n",
        "\n",
        "            epsilon = tf.random.uniform((batch_size, 1, 1, 1))\n",
        "            interpolates = epsilon * inputs + (1 - epsilon) * fake_images\n",
        "            gradient_tape.watch(interpolates)\n",
        "\n",
        "            interpolate_pred = self.discriminator(interpolates)\n",
        "            gradients = gradient_tape.gradient(interpolate_pred, [interpolates])\n",
        "            gp_loss = self.loss_weights['gradient_penalty'] * self.gradient_loss(gradients)\n",
        "\n",
        "            d_loss_fake = wasserstien_loss(fake_labels, pred_fake)\n",
        "            d_loss_real = wasserstien_loss(real_labels, pred_real)\n",
        "            \n",
        "            all_pred = tf.concat([pred_real, pred_fake], axis=0)\n",
        "            drift_loss = self.loss_weights['drift'] * tf.reduce_mean(all_pred ** 2)\n",
        "\n",
        "            d_loss = d_loss_fake + d_loss_real + gp_loss + drift_loss\n",
        "        \n",
        "        vars = self.discriminator.variables\n",
        "        gradients = tape.gradient(d_loss, vars)\n",
        "        self.d_optimizer.apply_gradients(zip(gradients, vars))\n",
        "\n",
        "        return {'g_loss': g_loss, 'd_loss': d_loss}\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        pass\n",
        "    \n",
        "    def generate_images(self, style_code=None, z=None, noise=None, batch_size = 1, alpha = 1.0):\n",
        "        if style_code is None:\n",
        "            if z is None:\n",
        "                z = tf.random.normal((batch_size, self.z_dim))\n",
        "            style_code = self.mapping(z)\n",
        "        \n",
        "        if not noise:\n",
        "            noise = self.generate_noise(batch_size)\n",
        "        \n",
        "        self.alpha.assign(alpha)\n",
        "\n",
        "        const_input = tf.ones(tuple([batch_size]+list(self.g_input_shape)))\n",
        "        images = self.generator([const_input, style_code, noise])\n",
        "        images = np.clip((images*0.5 + 0.5)*255, 0, 255).astype(np.uint8)\n",
        "\n",
        "        return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWDx_pSK4M14"
      },
      "source": [
        "START_RES = 8\n",
        "TARGET_RES = 256\n",
        "\n",
        "style_gan = StyleGAN(start_res=START_RES, \n",
        "                     target_res=TARGET_RES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arKHR1zz4dhX"
      },
      "source": [
        "opt_cfg = {'learning_rate':1e-3, 'beta_1':0.0, 'beta_2':0.99, 'epsilon':1e-8}\n",
        "\n",
        "val_z = tf.random.normal((16, style_gan.z_dim))  \n",
        "\n",
        "STEPS_PER_EPOCH = 10000\n",
        "\n",
        "start_res_log2 = int(np.log2(START_RES))\n",
        "target_res_log2 = int(np.log2(TARGET_RES))\n",
        "\n",
        "for res_log2 in range(start_res_log2, target_res_log2+1):\n",
        "    res = 2**res_log2\n",
        "    for phase in [Phase.TRANSITION, Phase.STABLE]:\n",
        "        if res==START_RES and phase==Phase.TRANSITION:\n",
        "            continue\n",
        "\n",
        "        train_ds = create_dataset(res)\n",
        "\n",
        "        steps = int(TRAIN_STEP_RATIO[res_log2] * STEPS_PER_EPOCH)\n",
        "\n",
        "        style_gan.compile(d_optimizer=Adam(**opt_cfg),\n",
        "                          g_optimizer=Adam(**opt_cfg), \n",
        "                          loss_weights = {'gradient_penalty':10, 'drift':0.001},\n",
        "                          steps_per_epoch=steps,\n",
        "                          res=res,\n",
        "                          phase=phase, run_eagerly=False)\n",
        "\n",
        "        prefix = f'res_{res}x{res}_{style_gan.phase}'\n",
        "\n",
        "        ckpt_cb = ModelCheckpoint(f'{CKPT_PATH}/stylegan_{res}x{res}.ckpt', \n",
        "                                  save_weights_only=True, verbose=1)\n",
        "        print(phase)\n",
        "        style_gan.fit(train_ds, epochs=1, \n",
        "                      steps_per_epoch=steps, callbacks=[ckpt_cb])\n",
        "        \n",
        "        images = style_gan.generate_images(z=val_z, alpha=1.0)\n",
        "        plot_images(images, res_log2, f\"{RESULT_PATH}/{prefix}.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_ZM2hyi4rhH",
        "outputId": "716c1edc-65d9-4dc9-ab0f-52eb75318fb2"
      },
      "source": [
        "#Loading pretrained model from author\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1-osEhEjIhHfegD9Uap00d23xlpV4cXqq'\n",
        "gdown.download(url, 'checkpoints.zip', quiet=False)\n",
        "!unzip checkpoints.zip -d ./pretrained"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-osEhEjIhHfegD9Uap00d23xlpV4cXqq\n",
            "To: /content/checkpoints.zip\n",
            "570MB [00:04, 128MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Archive:  checkpoints.zip\n",
            "  inflating: ./pretrained/stylegan_256x256.ckpt.data-00000-of-00002  \n",
            "  inflating: ./pretrained/stylegan_256x256.ckpt.data-00001-of-00002  \n",
            "  inflating: ./pretrained/stylegan_256x256.ckpt.index  \n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<__main__.ConvBlock object at 0x7f47bc3d15d0> and <keras.layers.core.Flatten object at 0x7f47bc35e690>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<__main__.DenseBlock object at 0x7f47bc364b10> and <__main__.DenseBlock object at 0x7f47bc368950>).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f47bc1689d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQsq3ZZQcgDF",
        "outputId": "e944f508-351b-496b-9fff-672b6deaf8f9"
      },
      "source": [
        "style_gan.grow_model(256)\n",
        "style_gan.load_weights('./pretrained/stylegan_256x256.ckpt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<__main__.ConvBlock object at 0x7f47ba2e6850> and <keras.layers.core.Flatten object at 0x7f47ba2f8390>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<__main__.DenseBlock object at 0x7f47ba2efd50> and <__main__.DenseBlock object at 0x7f47ba2f8310>).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f47ba253b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beMrDtYk5ay_"
      },
      "source": [
        "batch_size = 8\n",
        "z = tf.random.truncated_normal((batch_size, 512))\n",
        "w = style_gan.mapping(z)\n",
        "noise = style_gan.generate_noise(batch_size)\n",
        "images = style_gan.generate_images(style_code=w, noise=noise, alpha=1.)\n",
        "plot_images(images, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lW6nbnb51UX"
      },
      "source": [
        "# Select style from above\n",
        "idx_a = 1\n",
        "idx_b = 2\n",
        "w_a = np.expand_dims(w[idx_a], 0)\n",
        "w_b = np.expand_dims(w[idx_b], 0)\n",
        "noise_a = [np.expand_dims(n[idx_a],0) for n in noise]\n",
        "noise_b = [np.expand_dims(n[idx_b],0) for n in noise]\n",
        "\n",
        "image_a = style_gan.generate_images(style_code=w_a, noise=noise_a)[0]\n",
        "image_b = style_gan.generate_images(style_code=w_b, noise=noise_b)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVDwUKlN9upX"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interact_manual\n",
        "\n",
        "\n",
        "@interact\n",
        "def explore_latent_variable(a0 = (0,1.0,0.05),\n",
        "                            a1 = (0,1.0,0.05),\n",
        "                            a2 = (0,1.0,0.05),\n",
        "                            a3 = (0,1.0,0.05),\n",
        "                            a4 = (0,1.0,0.05),\n",
        "                            a5 = (0,1.0,0.05),\n",
        "                            noise_src = widgets.Select(options=['Left', 'Right'], value='Left', \n",
        "                                                       description='Pose from:')\n",
        "):\n",
        "    style_a = np.mean(w_a, axis=(0,1))\n",
        "    style_b = np.mean(w_b, axis=(0,1))\n",
        "    alphas = [a0, a1, a2, a3, a4, a5]\n",
        "    w_mix = np.expand_dims([alpha*style_a + (1-alpha)*style_b for alpha in alphas], 0)\n",
        "    noise = noise_a if noise_src == 'Right' else noise_b\n",
        "    image_mix = style_gan.generate_images(style_code=w_mix, noise=noise)[0]\n",
        "    images = np.stack([image_b, image_a, image_mix])\n",
        "    plot_images(images, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSPXovAo-Dif"
      },
      "source": [
        "noise = style_gan.generate_noise(batch_size)\n",
        "images = style_gan.generate_images(style_code=w_a, noise=noise)\n",
        "plot_images(images, 6)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}