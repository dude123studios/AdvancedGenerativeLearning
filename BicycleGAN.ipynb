{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BicycleGAN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzt/MhgYfsFvfmYCuhQKD2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dude123studios/AdvancedGenerativeLearning/blob/main/BicycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmmH49TbdABS",
        "outputId": "89f37e13-778a-4517-de10-fb6055c98186"
      },
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 679 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP2Zw7HPBAdZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.activations import relu, tanh\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.metrics import binary_accuracy\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiNcVVkMCxUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd37a05-3699-400a-c978-05603240e7c6"
      },
      "source": [
        "dataset_name = 'edges2shoes'\n",
        "_URL = f'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/{dataset_name}.tar.gz'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(f'{dataset_name}.tar.gz',\n",
        "                                      origin=_URL,\n",
        "                                      extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), f'{dataset_name}/')\n",
        "\n",
        "dataset_name = \"facades\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/edges2shoes.tar.gz\n",
            "2165284864/2165283376 [==============================] - 465s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEwqFX9rC0H1"
      },
      "source": [
        "image_shape = (256, 256, 3)\n",
        "IMG_HEIGHT = image_shape[0]\n",
        "IMG_WIDTH = image_shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7x6Y_PxDDfd"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "BUFFER_SIZE = 400\n",
        "\n",
        "def load(image_file):\n",
        "    image = tf.io.read_file(image_file)\n",
        "    image = tf.image.decode_jpeg(image)\n",
        "\n",
        "    w = tf.shape(image)[1]\n",
        "\n",
        "    w = w // 2\n",
        "    real_image = image[:, w:, :]\n",
        "    input_image = image[:, :w, :]\n",
        "\n",
        "    input_image = tf.cast(input_image, tf.float32)\n",
        "    real_image = tf.cast(real_image, tf.float32)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "def resize(input_image, real_image, height, width):\n",
        "    input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    real_image = tf.image.resize(real_image, [height, width],\n",
        "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "def random_crop(input_image, real_image):\n",
        "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "    cropped_image = tf.image.random_crop(\n",
        "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "\n",
        "    return cropped_image[0], cropped_image[1]\n",
        "\n",
        "def normalize(input_image, real_image):\n",
        "    input_image = (input_image / 127.5) - 1\n",
        "    real_image = (real_image / 127.5) - 1\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "#@tf.function()\n",
        "def random_jitter(input_image, real_image):\n",
        "    # resizing to 286 x 286 x 3\n",
        "    input_image, real_image = resize(input_image, real_image, 286, 286)\n",
        "\n",
        "    # randomly cropping to 256 x 256 x 3\n",
        "    input_image, real_image = random_crop(input_image, real_image)\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        # random mirroring\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        real_image = tf.image.flip_left_right(real_image)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "def load_image_train(image_file):\n",
        "    input_image, real_image = load(image_file)\n",
        "    input_image, real_image = random_jitter(input_image, real_image)\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "def load_image_test(image_file):\n",
        "    input_image, real_image = load(image_file)\n",
        "    input_image, real_image = resize(input_image, real_image,\n",
        "                                   IMG_HEIGHT, IMG_WIDTH)\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "train_dataset = tf.data.Dataset.list_files(PATH+'train/*.jpg')\n",
        "train_dataset = train_dataset.map(load_image_train,\n",
        "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.list_files(PATH+'val/*.jpg')\n",
        "test_dataset = test_dataset.map(load_image_test)\n",
        "test_dataset = test_dataset.batch(1).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YerjZ8yhGbg2"
      },
      "source": [
        "def downsample(channels, kernels, strides=2, norm=True, activation=True, dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    block = tf.keras.Sequential()\n",
        "    block.add(layers.Conv2D(channels, kernels, strides=strides, padding='same', \n",
        "                                use_bias=False, kernel_initializer=initializer))\n",
        "    \n",
        "    if norm:\n",
        "        block.add(InstanceNormalization())              \n",
        "    if activation:\n",
        "        block.add(layers.LeakyReLU(0.2)) \n",
        "    if dropout:\n",
        "        block.add(layers.Dropout(0.5))\n",
        "\n",
        "    return block\n",
        "\n",
        "def upsample(channels, kernels, strides=1, norm=True, activation=True, dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    block = tf.keras.Sequential()\n",
        "    block.add(layers.UpSampling2D((2,2)))\n",
        "    block.add(layers.Conv2D(channels, kernels, strides=strides, padding='same', \n",
        "                            use_bias=False, kernel_initializer=initializer))\n",
        "\n",
        "    if norm:\n",
        "        block.add(InstanceNormalization())              \n",
        "    if activation:\n",
        "        block.add(layers.LeakyReLU(0.2)) \n",
        "    if dropout:\n",
        "        block.add(layers.Dropout(0.5))\n",
        "\n",
        "    return block"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYilN2erJ_3P"
      },
      "source": [
        "def build_generator(z_dim, image_shape):\n",
        "\n",
        "    DIM = 64\n",
        "    input_image = layers.Input(shape=image_shape)\n",
        "    input_z = layers.Input(shape=(z_dim,), name='z')\n",
        "        \n",
        "    z = layers.Reshape((1,1, z_dim))(input_z)\n",
        "    z_tiles = tf.tile(z, [1, image_shape[0], image_shape[1], 8])\n",
        "    x = layers.Concatenate()([input_image, z_tiles])\n",
        "\n",
        "    down1 = downsample(DIM, 4, norm=False)(x)\n",
        "    down2 = downsample(2 * DIM, 4, norm=False)(down1)\n",
        "    down3 = downsample(4 * DIM, 4, norm=False)(down2)\n",
        "    down4 = downsample(4 * DIM, 4, norm=False)(down3)\n",
        "    down5 = downsample(4 * DIM, 4, norm=False)(down4)\n",
        "    down6 = downsample(4 * DIM, 4, norm=False)(down5)\n",
        "    down7 = downsample(4 * DIM, 4, norm=False)(down6)\n",
        "\n",
        "    up6 = upsample(4*DIM, 4, dropout=True)(down7)\n",
        "    concat6 = layers.Concatenate()([up6, down6]) \n",
        "\n",
        "    up5 = upsample(4*DIM, 4, dropout=True)(concat6)\n",
        "    concat5 = layers.Concatenate()([up5, down5]) \n",
        "    \n",
        "    up4 = upsample(4*DIM, 4)(concat5)\n",
        "    concat4 = layers.Concatenate()([up4, down4]) \n",
        "\n",
        "    up3 = upsample(4*DIM, 4)(concat4)\n",
        "    concat3 = layers.Concatenate()([up3, down3]) \n",
        "\n",
        "    up2 = upsample(2*DIM, 4)(concat3)\n",
        "    concat2 = layers.Concatenate()([up2, down2]) \n",
        "\n",
        "    up1 = upsample(DIM, 4)(concat2)\n",
        "    concat1 = layers.Concatenate()([up1, down1]) \n",
        "\n",
        "    output_image = tanh(upsample(3, 4, norm=False, activation=False)(concat1))\n",
        "\n",
        "    return Model([input_image, input_z], output_image, name='generator') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBgx4umBMa1G"
      },
      "source": [
        " def build_discriminator():\n",
        "    DIM = 64\n",
        "    input_image_B = layers.Input(shape=image_shape)\n",
        "        \n",
        "    x = downsample(DIM, 4, norm=False)(input_image_B) # 128\n",
        "    x = downsample(2*DIM, 4)(x) # 64\n",
        "    x = downsample(4*DIM, 4)(x) # 32\n",
        "    x =downsample(8*DIM, 4, strides=1)(x) \n",
        "    output = layers.Conv2D(1, 4)(x)\n",
        "\n",
        "    return Model(input_image_B, output, name='discriminator')     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zn0DsEDTDTr"
      },
      "source": [
        "class GaussianSampling(layers.Layer): \n",
        "    def __init__(self, z_dim, name):\n",
        "        super(GaussianSampling, self).__init__(name=name)\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        mean, logvar = inputs\n",
        "        epsilon = tf.random.normal((1, self.z_dim), mean=0., stddev=1.)\n",
        "        return mean + tf.exp(0.5 * logvar) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue0bbwykS0Q5"
      },
      "source": [
        "def build_encoder(z_dim):\n",
        "    DIM = 64\n",
        "    input_image = layers.Input(shape=image_shape)\n",
        "    x = downsample(DIM, 4, norm=False)(input_image) \n",
        "    x = downsample(2*DIM, 4)(x) \n",
        "    x = downsample(4*DIM, 4)(x) \n",
        "    x = downsample(8*DIM, 4)(x) \n",
        "    x = downsample(8*DIM, 4)(x) \n",
        "    x = downsample(8*DIM, 4)(x) \n",
        "    x = layers.Flatten()(x)\n",
        "    mean = layers.Dense(z_dim, name='mean')(x)\n",
        "    logvar = layers.Dense(z_dim, name='logvar')(x)\n",
        "    z = GaussianSampling(name='z', z_dim=z_dim)([mean, logvar])\n",
        "    return Model(input_image, [z, mean, logvar], name='encoder')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15noIo84Mbz2"
      },
      "source": [
        "class BicycleGAN(Model):\n",
        "\n",
        "    def __init__(self, image_shape, z_dim):\n",
        "        super(BicycleGAN, self).__init__()\n",
        "\n",
        "        self.image_shape = image_shape\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.discriminator_1 = build_discriminator()\n",
        "        self.discriminator_2 = build_discriminator()\n",
        "        self.encoder = build_encoder(z_dim)\n",
        "        self.generator = build_generator(z_dim, image_shape)\n",
        "\n",
        "        self.LAMBDA = 100\n",
        "\n",
        "        discriminator_output = self.discriminator_1([self.generator.output])\n",
        "        self.patch_size = discriminator_output.shape[1]\n",
        "\n",
        "    def compile(self):\n",
        "        super(BicycleGAN, self).compile()\n",
        "\n",
        "        self.LAMBDA_IMAGE = 10\n",
        "        self.LAMBDA_LATENT = 0.5\n",
        "        self.LAMBDA_KL = 0.01\n",
        "\n",
        "        self.d1_optimizer = Adam(2e-4, 0.5)\n",
        "        self.d2_optimizer = Adam(2e-4, 0.5)\n",
        "        self.g_optimizer = Adam(2e-4, 0.5)\n",
        "        self.e_optimizer = Adam(2e-4, 0.5)\n",
        "        \n",
        "        self.mae = tf.keras.losses.MeanAbsoluteError()\n",
        "        self.mse = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "        images_A, images_B = inputs\n",
        "        batch_size = tf.shape(images_A)[0]\n",
        "\n",
        "        images_A_1, images_A_2 = images_A[:batch_size // 2], images_A[batch_size // 2:]\n",
        "        images_B_1, images_B_2 = images_B[:batch_size //2], images_B[batch_size // 2:]\n",
        "\n",
        "        real_labels = tf.ones((batch_size, self.patch_size, self.patch_size, 1))\n",
        "        fake_labels = tf.zeros((batch_size, self.patch_size, self.patch_size, 1))\n",
        "\n",
        "        z = tf.random.normal((batch_size, self.z_dim))\n",
        "\n",
        "        with tf.GradientTape() as d1_tape, \\\n",
        "            tf.GradientTape() as d2_tape, \\\n",
        "            tf.GradientTape() as g_tape, \\\n",
        "            tf.GradientTape() as e_tape:\n",
        "\n",
        "            # cVAE-GAN\n",
        "            z_encode, mean_encode, logvar_encode = self.encoder(images_B_1)\n",
        "            kl_loss =  - 0.5 * tf.reduce_sum(1 + logvar_encode - \\\n",
        "                                          tf.square(mean_encode) - tf.exp(logvar_encode))\n",
        "            \n",
        "            fake_B_encode = self.generator([images_A_1, z_encode])\n",
        "\n",
        "            encode_fake = self.discriminator_1(fake_B_encode)\n",
        "            encode_real = self.discriminator_1(images_B_1)\n",
        "\n",
        "            # cLR-GAN\n",
        "            fake_B_random = self.generator([images_A_2, z])\n",
        "            _, mean_random, _ = self.encoder(fake_B_random)\n",
        "\n",
        "            random_fake = self.discriminator_2(fake_B_random)\n",
        "            random_real = self.discriminator_2(images_B_2)\n",
        "\n",
        "            d1_loss = self.mse(encode_fake, fake_labels) + self.mse(encode_real, real_labels)\n",
        "            d2_loss = self.mse(random_fake, fake_labels) + self.mse(random_real, real_labels)\n",
        "\n",
        "            g_1_loss = self.mse(encode_fake, real_labels)\n",
        "            g_2_loss = self.mse(random_fake, real_labels)\n",
        "\n",
        "            image_loss = self.LAMBDA_IMAGE * self.mae(images_B_1, fake_B_encode)\n",
        "            kl_loss = self.LAMBDA_KL * (- 0.5 * tf.reduce_sum(1 + logvar_encode - \\\n",
        "                                          tf.square(mean_encode) - tf.exp(logvar_encode)))\n",
        "            \n",
        "            latent_loss = self.LAMBDA_LATENT * self.mae(z, mean_random)\n",
        "            \n",
        "            e_loss = g_1_loss + g_2_loss + image_loss + kl_loss\n",
        "            g_loss = e_loss + latent_loss\n",
        "        \n",
        "\n",
        "        d1_grads = d1_tape.gradient(d1_loss, self.discriminator_1.trainable_variables)\n",
        "        d2_grads = d2_tape.gradient(d2_loss, self.discriminator_2.trainable_variables)\n",
        "\n",
        "        g_grads = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "        e_grads = e_tape.gradient(e_loss, self.encoder.trainable_variables)\n",
        "\n",
        "        self.d1_optimizer.apply_gradients(zip(d1_grads, self.discriminator_1.trainable_variables))\n",
        "        self.d2_optimizer.apply_gradients(zip(d2_grads, self.discriminator_2.trainable_variables))\n",
        "\n",
        "        self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_variables))\n",
        "        self.e_optimizer.apply_gradients(zip(e_grads, self.encoder.trainable_variables))\n",
        "\n",
        "        return {'g_loss': g_loss, 'd_loss': (d1_loss + d2_loss)/2}\n",
        "    \n",
        "    def call(self, input_imgs):\n",
        "        num_imgs = tf.shape(input_imgs)[0]\n",
        "        z = tf.random.normal((num_imgs, self.z_dim))\n",
        "        return self.generator([input_imgs, z])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub2F4cI-ax1t"
      },
      "source": [
        "class GenerativeCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, test_dataset, num_imgs=5, interval=5):\n",
        "        super(GenerativeCallback, self).__init__()\n",
        "        \n",
        "        self.num_imgs = num_imgs\n",
        "        self.interval = interval\n",
        "        self.ds = iter(test_dataset)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch % self.interval) is not 0:\n",
        "            return \n",
        "        grid_row = 1\n",
        "        grid_col = self.num_imgs\n",
        "        batch, _ = next(self.ds)\n",
        "        images = self.model(batch)\n",
        "        f, axarr = plt.subplots(grid_row, grid_col, figsize=(grid_col*1.5, grid_row*1.5))\n",
        "        for col in range(grid_col):\n",
        "            axarr[col].imshow((images[col,:,:,:]+1)/2)\n",
        "            axarr[col].axis('off') \n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20JcT0Mpbpfy"
      },
      "source": [
        "bicyclegan = BicycleGAN(image_shape, z_dim=8)\n",
        "\n",
        "bicyclegan.compile()\n",
        "callbacks = [GenerativeCallback(test_dataset)]\n",
        "\n",
        "bicyclegan.fit(train_dataset, epochs=30, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}